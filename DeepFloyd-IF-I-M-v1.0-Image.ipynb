{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/DeepFloyd-IF-colab/blob/main/DeepFloyd-IF-I-M-v1.0-Image.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DA4ASNpIvTzd"
      },
      "outputs": [],
      "source": [
        "# https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/deepfloyd_if_free_tier_google_colab.ipynb modified\n",
        "!pip install -q -U diffusers~=0.16 transformers~=4.28 safetensors~=0.3 sentencepiece~=0.1 accelerate~=0.18 bitsandbytes~=0.38 torch~=2.0 huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69qUFyBkwKs0"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import T5EncoderModel\n",
        "\n",
        "text_encoder = T5EncoderModel.from_pretrained(\n",
        "    \"DeepFloyd/IF-I-XL-v1.0\",\n",
        "    subfolder=\"text_encoder\", \n",
        "    device_map=\"auto\", \n",
        "    load_in_8bit=True, \n",
        "    variant=\"8bit\"\n",
        ")\n",
        "\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    \"DeepFloyd/IF-I-XL-v1.0\", \n",
        "    text_encoder=text_encoder, # pass the previously instantiated 8bit text encoder\n",
        "    unet=None, \n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "prompt = 'a photograph of an astronaut riding a horse holding a sign that says \"Pixel\\'s in space\"'\n",
        "\n",
        "prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)\n",
        "\n",
        "del text_encoder\n",
        "del pipe\n",
        "\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "def flush():\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flush()\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    \"DeepFloyd/IF-I-XL-v1.0\", \n",
        "    text_encoder=None, \n",
        "    variant=\"fp16\", \n",
        "    torch_dtype=torch.float16, \n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "generator = torch.Generator().manual_seed(1)\n",
        "\n",
        "image = pipe(\n",
        "    prompt_embeds=prompt_embeds,\n",
        "    negative_prompt_embeds=negative_embeds, \n",
        "    output_type=\"pt\",\n",
        "    generator=generator,\n",
        ").images\n",
        "\n",
        "from diffusers.utils import pt_to_pil\n",
        "\n",
        "pil_image = pt_to_pil(image)\n",
        "\n",
        "pil_image[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del pipe\n",
        "flush()\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    \"DeepFloyd/IF-II-L-v1.0\", \n",
        "    text_encoder=None, # no use of text encoder => memory savings!\n",
        "    variant=\"fp16\", \n",
        "    torch_dtype=torch.float16, \n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "image = pipe(\n",
        "    image=image, \n",
        "    prompt_embeds=prompt_embeds, \n",
        "    negative_prompt_embeds=negative_embeds, \n",
        "    output_type=\"pt\",\n",
        "    generator=generator,\n",
        ").images\n",
        "\n",
        "pil_image = pt_to_pil(image)\n",
        "\n",
        "pil_image[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del pipe\n",
        "flush()\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-x4-upscaler\", \n",
        "    torch_dtype=torch.float16, \n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "pil_image = pipe(prompt, generator=generator, image=image).images\n",
        "\n",
        "pil_image[0]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
